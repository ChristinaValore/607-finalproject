---
title: 'Data 607: Final Project'
author: "Anthony Munoz, Christina Valore, David Apolinar."
date: "5/10/2019"
output: 
  html_document:
    #df_print: paged
    toc: true # table of content true
    toc_collapsed : false
    toc_float: true
    code_folding : show
    toc_depth: 3  # upto three depths of headings (specified by #, ## and ###)
    number_sections: true  ## if you want number sections at each table header
    smooth_scroll: true
    theme: cerulean  # many options for theme, this one is my favorite.
    highlight: textmate  # specifies the syntax highlighting style
---

```{r setup, include=FALSE}
library(mongolite)
library(magrittr)
library(dplyr)
library(tidyr)
```

# Project Overview

NYC Subway delays have been constantly scrutinized for being delayed all the time. There are daily articles published criticizing the MTA for not doing enough to resolve the constant delays that plague the 100+ year aging subway system. To make matters worse, there is constant scrutiny over the MTA overpaying its workers and not contributing to repairing its infrastructure.

* https://patch.com/new-york/new-york-city/nyc-subway-delays-8-lines-messed-during-morning-rush
* https://www.cbsnews.com/news/new-york-struggling-transit-agency-mta-paid-one-worker-344k-in-overtime/

As part of this analysis, we want to determine what could be the causes of the NYC Subway system. We gathered data from several locations, including the MTA's own published performance metrics.

# Business Question


As part of this analysis, we want to answer the following questions?

* Is the time of the year predicitive of the NYC subway on-time performance (OTP)?
* Are there other factors contributing to the delays?
  
  * weather impact

Using some of the collected data, we want to detemrine whether there may be external factors that may show some level of correlation with they delays. It's quite possible that it may not be the case, but this is why we analyze the data to come to a conclusion.

# Obtain the Data

Data was obtained from several locations:

* MTA Performance Data

This dataset included the following items:

**Subway**

  *  Subway wait assessment for all lines
  *  Customer Injury Rate
  *  Elevator availability
  *  Escalator Availability
  *  Mean Distance Between Failure
  *  On-Time Performance, total and for all lines
  *  Total Ridership

http://web.mta.info/developers/performance.html

**Average Monthly and Annual Temperates at Centrak Park, NY**

This data set includes all monthly averages from 1869 to 2018

https://www.weather.gov/media/okx/Climate/CentralPark/monthlyannualtemp.pdf

**Projected Population Data**

While there is no accurate source of population per year, we based our population data from the 2010 census with projections built-in for each year.

http://worldpopulationreview.com/us-cities/new-york-city-population


### Subway Data Processing


```{r MTA}
# load data
data<- read.csv("https://raw.githubusercontent.com/ChristinaValore/stats-prob-606/master/Performance_NYCT.csv", header=TRUE, check.names = FALSE)

# subsetting the data to only pull out the OTP (ON TIME %)
sub <-data[ which(data$PARENT_SEQ=='391690'), ]

head(sub,10)

# remove columns that are not needed for this analysis
sub<- sub[c(-1:-3, -5:-10)]

# check for the completeness of the data by checking how many subways were analyzed
unique(sub$INDICATOR_NAME)

# 24 subways were analyzed over 12 months so each year should have 288 values
table(sub$PERIOD_YEAR) 

# See if OTP was measured for all subway lines
table(sub$INDICATOR_NAME)

# we would like the data to be as similar as possible so we will remove the years 2009 and 2010 as they have the least data and standardize the remainder of the years be removing incomplete subway lines: S line 42 and the W line
sub.updated<-sub %>% 
  filter(PERIOD_YEAR >= "2011", INDICATOR_NAME != "OTP (Terminal) - W Line", INDICATOR_NAME != "OTP (Terminal) - S Line 42 St.")

# check on the data once more for completeness
table(sub.updated$PERIOD_YEAR) 
table(sub.updated$PERIOD_MONTH) 

```

## Weather Data Processing

To process the weather data, we decided to convert to a CSV and store it directly on a MongoDB instance running in Microsoft Azure. This made it easy to filter based on the year using the following query:

* weather.2017<-mgo$find('{"YEAR":{"$gt":2007}}')

The resulting values were stored into a dataframe and then converted from wide to long format using tidyverse gather

```{r mongo}
#file.old <- "/Users/davidapolinar/Dropbox/CUNYProjects/Srping2019/Data607/FinalProject/monthlyannualtemp-converted.csv"
file <- "https://raw.githubusercontent.com/dapolloxp/607-finalproject/master/monthlyannualtemp-converted.csv"

weather.data = read.csv(file, stringsAsFactors = FALSE)
cleaned.weather <- weather.data %>% select(-11)
missing.days <- c(77.5, 76, 68.5, 57.5, 47.5, 38)
cleaned.weather[150,8:13] <- missing.days
cleaned.weather[150,14] <- apply(cleaned.weather[10,2:13],1,mean)

#mongo_pwd_file <- "/Users/christinavalore/Desktop/password.txt"
mongo_pwd_file <- "/Users/davidapolinar/Dropbox/CUNYProjects/Srping2019/Data607/Week 13/mongopassword.txt"

mongo_password <-read.delim(mongo_pwd_file, header = FALSE, stringsAsFactors = FALSE)

#url <- paste0("mongodb://nyc.admin:", mongo_password$V1 , "@52.167.52.62:27017/weather",sep = "")
url <- paste0("mongodb://nyc.admin:", mongo_password$V1 , "@10.20.1.6:27017/weather",sep = "")
mgo <- mongo(collection = "nyc", db = "weather",  url=url, verbose = TRUE)
mgo$drop()
mgo$insert(cleaned.weather)

weather.2017<-mgo$find('{"YEAR":{"$gt":2007}}')

mgo$find('{"YEAR":{}}')
```

```{r}
weather.2017.cleaned <- weather.2017 %>% select(-ANNUAL)
new <- gather(weather.2017.cleaned , 'JAN', 'FEB', 'MAR', 'APR','MAY','JUN','JUL','AUG', 'SEP','OCT','NOV','DEC',key = 'Month', value = 'Avg Monthly Temp')
```

**Before Converting the data from wide to long:**



```{r}
weather.2017
```

**After the conversion:**

```{r}
head(new %>% arrange(YEAR),n=20)

new [new== "JAN"]<-1
new [new== "FEB"]<-2
new [new== "MAR"]<-3
new [new== "APR"]<-4
new [new== "MAY"]<-5
new [new== "JUN"]<-6
new [new== "JUL"]<-7
new [new== "AUG"]<-8
new [new== "SEP"]<-9
new [new== "OCT"]<-10
new [new== "NOV"]<-11
new [new== "DEC"]<-12

new<-new %>%
  rename(
    PERIOD_YEAR = YEAR,
   PERIOD_MONTH = Month
  )

new.weather<-new %>% 
  filter(PERIOD_YEAR >= "2011" & PERIOD_YEAR <="2017")
```
## Population Data Processing

The data was retrieved from the following web link: 

http://worldpopulationreview.com/us-cities/new-york-city-population

To process this data, we had to use the RVest libraries to process the HTML tables. This made the processing extremely simple. While RVest gathered all tables, we were able to filter the rows that we are interested in:


```{r population}
library(rvest)
population.data <- read_html("http://worldpopulationreview.com/us-cities/new-york-city-population")
pop.table <-population.data %>% html_nodes("table") %>% .[[1]] %>% html_table()
expected.growth <-pop.table[2:9,1:2]
names(expected.growth) <- pop.table[1,1:2]

expected.growth

```

# Cleansing

```{r}
## Once we have all the data - we can attempt to combine all a do a futher cleansing process as needed.

# check the structure of the two frames before merging as year and month variable types must match before merge
str(sub.updated)
str(new.weather)

sub.updated$PERIOD_YEAR<-as.factor(sub.updated$PERIOD_YEAR)
sub.updated$PERIOD_MONTH<-as.factor(sub.updated$PERIOD_MONTH)
new.weather$PERIOD_YEAR<-as.factor(new.weather$PERIOD_YEAR)
new.weather$PERIOD_MONTH<-as.factor(new.weather$PERIOD_MONTH)

# combine the two dataframes
combined<-left_join(sub.updated, new.weather, by= c("PERIOD_YEAR", "PERIOD_MONTH"))

#rename avg monthly temp column to conform to caps standards
combined<-combined %>%
  rename(
 MONTHLY_TEMP=`Avg Monthly Temp`
  )

# compare the monthly actual OTP to the monthly target OTP and if the actual is >= then the value is true, or the subway was on time for that month or in the ridership case, there was more riders than targeted
combined$ON_TIME <- as.numeric(combined$MONTHLY_ACTUAL >= combined$MONTHLY_TARGET)

# change percenmtages to decimals
combined$MONTHLY_TARGET <-  combined$MONTHLY_TARGET/100
combined$MONTHLY_ACTUAL <-  combined$MONTHLY_ACTUAL/100
combined$YTD_TARGET <-  combined$YTD_TARGET/100
combined$YTD_ACTUAL <-  combined$YTD_ACTUAL/100

# approximately 20 weekdays in a month as the OTP is only measured for weekdays
combined$DAYS_ON_TIME<-combined$MONTHLY_ACTUAL*20

# aggregate the values to see avg's by month
agg.combined<- aggregate(list(DAYS_ON_TIME=combined$DAYS_ON_TIME,MONTHLY_TEMP=combined$MONTHLY_TEMP), by= list(PERIOD_MONTH=combined$PERIOD_MONTH), FUN=mean)

agg.combined$PERIOD_MONTH<- as.factor(agg.combined$PERIOD_MONTH)
```


# Exploration

```{r ggplot}
library(ggplot2)
library(ggthemes)

# plot shows a curve in the values, linear regression might not be best
plot(x=agg.combined$MONTHLY_TEMP,y=agg.combined$DAYS_ON_TIME,xlab = "Monthly Temp", ylab="% Days On Time")

# scatter plot 
scatter.smooth(x=agg.combined$MONTHLY_TEMP,y=agg.combined$DAYS_ON_TIME, xlab = "Monthly Temperature", ylab="% Days On Time")

# boxplot to see outliers
par(mfrow=c(1, 2))  # divide graph area in 2 columns
boxplot(x=agg.combined$MONTHLY_TEMP,sub=paste("Outlier rows: ", boxplot.stats(x=agg.combined$MONTHLY_TEMP)$out))  
boxplot(agg.combined$DAYS_ON_TIME, sub=paste("Outlier rows: ", boxplot.stats(agg.combined$DAYS_ON_TIME)$out))  

# density plot 
library(e1071)
par(mfrow=c(1, 2))  # divide graph area in 2 columns

plot(density(agg.combined$MONTHLY_TEMP), main="Density Plot: MONTHLY TEMP", ylab="Frequency", sub=paste("Skewness:", round(e1071::skewness(agg.combined$MONTHLY_TEMP), 3)))  
polygon(density(agg.combined$MONTHLY_TEMP), col="red")

plot(density(agg.combined$DAYS_ON_TIME), main="Density Plot: DAYS ON TIME", ylab="Frequency", sub=paste("Skewness:", round(e1071::skewness(agg.combined$DAYS_ON_TIME), 3)))  
polygon(density(agg.combined$DAYS_ON_TIME), col="red")

# the correlation is weak between the subway days on time and the monthly temp at 20%
cor(agg.combined$MONTHLY_TEMP,agg.combined$DAYS_ON_TIME)

```

# Modeling 
```{r}

# Linear model: DAYS_ON_TIME =  0.003394 * MONTHLY_TEMP + 14.672797 
fit<- lm(DAYS_ON_TIME ~ MONTHLY_TEMP, agg.combined)
summary(fit) 

# Plot the values with a best fit line
plot(DAYS_ON_TIME ~ MONTHLY_TEMP, agg.combined, xlab="Monthly temperature", ylab="Subway days on-time", main="Temperature vs. Days On-time")
abline(fit)

# residual analysis 
plot(fit$fitted.values, fit$residuals, xlab="Fitted Values", ylab="Residuals",
     main="Fitted Values vs. Residuals")

qqnorm(fit$residuals)
qqline(fit$residuals)

# can we transform into a better fit?
fit2 <- lm(DAYS_ON_TIME ~ poly(MONTHLY_TEMP,2, raw=TRUE), agg.combined)
summary(fit2) 

fit3 <- lm(DAYS_ON_TIME ~ poly(MONTHLY_TEMP,3, raw=TRUE), agg.combined)
summary(fit3) 

# this polynomial has the best fit, with R2 of approx. 12%
fit4<-lm(DAYS_ON_TIME ~ poly(MONTHLY_TEMP,4, raw=TRUE), agg.combined)
summary(fit4) 

xx <- seq(0,80, length=50)
plot(x=agg.combined$MONTHLY_TEMP,y=agg.combined$DAYS_ON_TIME)
lines(xx, predict(fit, data.frame(MONTHLY_TEMP=xx)), col="red")
lines(xx, predict(fit2, data.frame(MONTHLY_TEMP=xx)), col="green")
lines(xx, predict(fit3, data.frame(MONTHLY_TEMP=xx)), col="blue")
lines(xx, predict(fit4, data.frame(MONTHLY_TEMP=xx)), col="purple")

```


# Interpretation

Is weather a predictor of the NYC subway's on time percentage (OTP)?

**Outliners:**

Our data for monthly temperatures and on-time delays appears to have several outliers, but it is much more pronounced with the OTP data towards the lower end.

**Observation:**

Our initial scatterplot of monthly temperature vs. days on-time seems to indicate that there is a slight positive train, but based the on the polynomial regression model above, we can see that there isn't a direct relationship of temperature to train delays. In fact, the R2 of the model accounts for 12% of the variability. 




# Conclusion

